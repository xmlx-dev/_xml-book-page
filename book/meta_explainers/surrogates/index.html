
<!DOCTYPE html>


<html lang="en" data-content_root="../../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>1. Surrogates &#8212; eXplainable&lt;br&gt;Machine Learning</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-design.min.css?v=87e54e7c" />
    <link rel="stylesheet" type="text/css" href="../../../_static/xmlx.css?v=cffff2e3" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../_static/copybutton.js?v=9d383507"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../_static/design-tabs.js?v=f930bc37"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-6635EH38S9"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-6635EH38S9');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-6635EH38S9');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"tex": {"macros": {"IR": "\\mathit{IR}", "argmin": "\\mathop{\\operatorname{arg\\,min}}\\limits", "argmax": "\\mathop{\\operatorname{arg\\,max}}\\limits"}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'book/meta_explainers/surrogates/index';</script>
    <link rel="canonical" href="https://book.xmlx.dev/book/meta_explainers/surrogates/index.html" />
    <link rel="icon" href="../../../_static/bulb.svg"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="1.1. Overview" href="intro.html" />
    <link rel="prev" title="Meta-Explainers" href="../index.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../README.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../../_static/bulb.svg" class="logo__image only-light" alt="eXplainable<br>Machine Learning - Home"/>
    <script>document.write(`<img src="../../../_static/bulb.svg" class="logo__image only-dark" alt="eXplainable<br>Machine Learning - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../README.html">
                    eXplainable Machine Learning
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../preface/index.html">Preface</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../preface/glossary.html">Glossary</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../preface/preliminary.html">Preliminary Information</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../preface/data.html">Modules, Data Sets and Models</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../index.html">Meta-Explainers</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2 current active has-children"><a class="current reference internal" href="#">1. Surrogates</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="intro.html">1.1. Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="text.html">1.2. Text Surrogates</a></li>
<li class="toctree-l3"><a class="reference internal" href="image.html">1.3. Image Surrogates</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="tabular/index.html">1.4. Tabular Surrogates</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="tabular/interpretable_representation.html">1.4.1. Binary Interpretable Representations for Tabular Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="tabular/data_sampling.html">1.4.2. Data Sampling</a></li>
<li class="toctree-l4"><a class="reference internal" href="tabular/explanation_generation.html">1.4.3. Explanation Generation</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="examples/index.html">1.5. Interactive Examples</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="examples/ex_tabular.html">1.5.1. Surrogate Explainer of Tabular Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples/ex_ols.html">1.5.2. Investigating Linear Surrogate Explainers of Tabular Data</a></li>
</ul>
</details></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../bibliography/bibliography.html">Bibliography</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../genindex.html">Index</a></li>
<li class="toctree-l1"><a class="reference external" href="https://book.xmlx.dev/docs/">XML Book Documentation</a></li>
<li class="toctree-l1"><a class="reference external" href="https://xmlx.dev/">XMLX Homepage</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/xmlx-dev/xml-book/master?urlpath=lab/tree/book/meta_explainers/surrogates/index.md" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Binder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Binder logo" src="../../../_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
      
      
      
      <li><a href="https://colab.research.google.com/github/xmlx-dev/xml-book/blob/master/book/meta_explainers/surrogates/index.md" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Colab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Colab logo" src="../../../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/xmlx-dev/xml-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/xmlx-dev/xml-book/edit/master/book/meta_explainers/surrogates/index.md" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/xmlx-dev/xml-book/issues/new?title=Issue%20on%20page%20%2Fbook/meta_explainers/surrogates/index.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../_sources/book/meta_explainers/surrogates/index.ipynb" target="_blank"
   class="btn btn-sm btn-download-notebook-button dropdown-item"
   title="Download notebook file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-code"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li><a href="../../../_sources/book/meta_explainers/surrogates/index.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>

</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Surrogates</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="surrogates">
<span id="text-meta-explainers-surrogates"></span><h1><span class="section-number">1. </span>Surrogates<a class="headerlink" href="#surrogates" title="Link to this heading">#</a></h1>
<div class="important dropdown admonition">
<p class="admonition-title">Explainer Summary</p>
<p>Surrogate explainers construct an inherently interpretable model to approximate a more complex, opaque decision boundary in a desired subspace.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p><em>Property</em></p></th>
<th class="head"><p><strong>Surrogate Explainers</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><em>relation</em></p></td>
<td><p>post-hoc</p></td>
</tr>
<tr class="row-odd"><td><p><em>compatibility</em></p></td>
<td><p>model-agnostic / (semi-)supervised</p></td>
</tr>
<tr class="row-even"><td><p><em>modelling</em></p></td>
<td><p>regression, crisp and probabilistic classification</p></td>
</tr>
<tr class="row-odd"><td><p><em>scope</em></p></td>
<td><p>local, cohort or global</p></td>
</tr>
<tr class="row-even"><td><p><em>target</em></p></td>
<td><p>prediction or model</p></td>
</tr>
<tr class="row-odd"><td><p><em>data</em></p></td>
<td><p>text, image or tabular (data-universal)</p></td>
</tr>
<tr class="row-even"><td><p><em>features</em></p></td>
<td><p>numerical and categorical (tabular data)</p></td>
</tr>
<tr class="row-odd"><td><p><em>explanation</em></p></td>
<td><p>type depends on the surrogate model</p></td>
</tr>
<tr class="row-even"><td><p><em>caveats</em></p></td>
<td><p>random sampling, explanation faithfulness</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<p>Surrogate explainers construct an inherently interpretable model in a desired – local, cohort or global – subspace to approximate a more complex, black-box decision boundary <span id="id1">[<a class="reference internal" href="../../bibliography/bibliography.html#id5" title="Mark Craven and Jude W Shavlik. Extracting tree-structured representations of trained networks. In Advances in neural information processing systems, 24–30. 1996.">Craven and Shavlik, 1996</a>; <a class="reference internal" href="../../bibliography/bibliography.html#id12" title="Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. “Why should I trust you?”: Explaining the predictions of any classifier. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, San Francisco, CA, USA, August 13-17, 2016, 1135–1144. 2016.">Ribeiro <em>et al.</em>, 2016</a>; <a class="reference internal" href="../../bibliography/bibliography.html#id16" title="Kacper Sokol, Alexander Hepburn, Raul Santos-Rodriguez, and Peter Flach. bLIMEy: Surrogate prediction explanations beyond LIME. 2019 Workshop on Human-Centric Machine Learning (HCML 2019) at the 33rd Conference on Neural Information Processing Systems (NeurIPS 2019), Vancouver, Canada, 2019. arXiv preprint arXiv:1910.13016. URL: https://arxiv.org/abs/1910.13016.">Sokol <em>et al.</em>, 2019</a>]</span>.
An intuitive visualisation of this process for tabular data is shown in <a class="reference internal" href="#fig-surrogates-overview"><span class="std std-numref">Figure 1.1</span></a>, where the red and blue areas capture two different classes determined by two continuous features.
While in this example the surrogate is a <em>linear</em> model fitted <em>locally</em> within a specific neighbourhood, different classifiers can be used to generate other types of explanations – while linear models offer feature influence <span id="id2">[<a class="reference internal" href="../../bibliography/bibliography.html#id12" title="Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. “Why should I trust you?”: Explaining the predictions of any classifier. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, San Francisco, CA, USA, August 13-17, 2016, 1135–1144. 2016.">Ribeiro <em>et al.</em>, 2016</a>]</span>, decision trees, for example, can provide feature importance and counterfactuals <span id="id3">[<a class="reference internal" href="../../bibliography/bibliography.html#id2" title="Kacper Sokol and Peter Flach. LIMEtree: Interactively customisable explanations based on local surrogate multi-output regression trees. arXiv preprint arXiv:2005.01427, 2020. URL: https://arxiv.org/abs/2005.01427.">Sokol and Flach, 2020</a>; <a class="reference internal" href="../../bibliography/bibliography.html#id13" title="Jasper van der Waa, Marcel Robeer, Jurriaan van Diggelen, Matthieu Brinkhuis, and Mark Neerincx. Contrastive explanations with local foil trees. Workshop on Human Interpretability in Machine Learning (WHI 2018) at the 35th International Conference on Machine Learning (ICML 2018), Stockholm, Sweden, 2018. arXiv preprint arXiv:1806.07470. URL: https://arxiv.org/abs/1806.07470.">van der Waa <em>et al.</em>, 2018</a>]</span>.
Furthermore, this simplistic depiction of surrogates should not be taken at its face value as these explainers often rely on custom <em><a class="reference internal" href="../../preface/glossary.html#term-interpretable-representation"><span class="xref std std-term">interpretable representations</span></a></em> – which transform raw features into human-intelligible concepts <span id="id4">[<a class="reference internal" href="../../bibliography/bibliography.html#id3" title="Kacper Sokol and Peter Flach. Interpretable representations in explainable AI: From theory to practice. arXiv preprint arXiv:2008.07007, 2020. URL: http://arxiv.org/abs/2008.07007.">Sokol and Flach, 2020</a>]</span> – in which case understanding their behaviour as well as properties and limitations of the resulting explanations require more nuance.
If poorly fitted, the surrogate model may output untrustworthy (and possibly misleading) insights, therefore its <em><a class="reference internal" href="../../preface/glossary.html#term-fidelity"><span class="xref std std-term">fidelity</span></a></em> – which captures the quality of black-box decision boundary approximation – should be evaluated and maximised <span id="id5">[<a class="reference internal" href="../../bibliography/bibliography.html#id15" title="Cynthia Rudin. Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead. Nature Machine Intelligence, 1(5):206–215, 2019.">Rudin, 2019</a>]</span>.
For the example shown in <a class="reference internal" href="#fig-surrogates-overview"><span class="std std-numref">Figure 1.1</span></a> this property is determined by the alignment between the dashed line (surrogate model) and the fragment of the red–blue decision boundary of the black box chosen to be explained.</p>
<figure class="align-default" id="fig-surrogates-overview" style="width: 95%">
<img alt="../../../_images/a89627344c1eed34fa2fe6052d9a861e6593a65e16150c648f3c7578555c279a.svg" src="../../../_images/a89627344c1eed34fa2fe6052d9a861e6593a65e16150c648f3c7578555c279a.svg" />
<figcaption>
<p><span class="caption-number">Figure 1.1 </span><span class="caption-text">A visualisation of a <em>local</em>, <em>linear</em> surrogate model – the black, dashed line – for two-dimensional tabular data with two classes.
The explanation is generated by extracting feature coefficients from this model.</span><a class="headerlink" href="#fig-surrogates-overview" title="Link to this image">#</a></p>
</figcaption>
</figure>
<!-- :alt: "Local, linear surrogate explainer for two-dimensional tabular data." -->
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>While <a class="reference internal" href="#fig-surrogates-overview"><span class="std std-numref">Figure 1.1</span></a> offers a good idea of surrogate explainers, this intuition may be misleading when dealing with their more complex instantiations.
For example, if they are built atop an <a class="reference internal" href="../../preface/glossary.html#term-interpretable-representation"><span class="xref std std-term">interpretable representation</span></a>, they do not <em>directly</em> approximate a black-box decision surface but instead capture its behaviour through the prism of concepts encoded by the interpretable representation.</p>
</div>
<h2> Overview of Surrogate Explainers </h2>
<p>Surrogates are an attractive explainability approach as they are <em>post-hoc</em> and <em>model-agnostic</em>, i.e., they can be retrofitted into a preëxisting black-box model regardless of its type.
Additionally, they can be applied to a range of diverse modelling problems across regression as well as crisp and probabilistic classification tasks.
Surrogate explainers are also <em>data-universal</em> due to the use of interpretable representations, therefore they work with text, image and tabular (with both numerical and categorical features) data.
For text and tabular data their local, cohort or global scope can be easily adjusted; however, for images they are predominantly local, i.e., valid only with respect to a single image.
This flexibility allows them to target an individual prediction, a group thereof, or scale up all the way to mimicking, hence simplifying, an entire black-box model.</p>
<p>A wide selection of transparent models that can be used as surrogates enables these explainers to provide a broad range of explanation types.
For example, decision trees can offer <a class="reference internal" href="../../preface/glossary.html#term-counterfactual"><span class="xref std std-term">counterfactuals</span></a> and <a class="reference internal" href="../../preface/glossary.html#term-feature-importance"><span class="xref std std-term">feature importance</span></a> <span id="id6">[<a class="reference internal" href="../../bibliography/bibliography.html#id2" title="Kacper Sokol and Peter Flach. LIMEtree: Interactively customisable explanations based on local surrogate multi-output regression trees. arXiv preprint arXiv:2005.01427, 2020. URL: https://arxiv.org/abs/2005.01427.">Sokol and Flach, 2020</a>; <a class="reference internal" href="../../bibliography/bibliography.html#id13" title="Jasper van der Waa, Marcel Robeer, Jurriaan van Diggelen, Matthieu Brinkhuis, and Mark Neerincx. Contrastive explanations with local foil trees. Workshop on Human Interpretability in Machine Learning (WHI 2018) at the 35th International Conference on Machine Learning (ICML 2018), Stockholm, Sweden, 2018. arXiv preprint arXiv:1806.07470. URL: https://arxiv.org/abs/1806.07470.">van der Waa <em>et al.</em>, 2018</a>]</span>, whereas linear classifiers deliver <a class="reference internal" href="../../preface/glossary.html#term-feature-influence"><span class="xref std std-term">feature influence</span></a> <span id="id7">[<a class="reference internal" href="../../bibliography/bibliography.html#id12" title="Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. “Why should I trust you?”: Explaining the predictions of any classifier. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, San Francisco, CA, USA, August 13-17, 2016, 1135–1144. 2016.">Ribeiro <em>et al.</em>, 2016</a>]</span>.
While this diversity may be alluring, it comes at a cost.
Since the explanations are extracted from a surrogate model, they may not be truthful with respect to the underlying black box, i.e., exhibit <strong>poor</strong> <em>fidelity</em>.
Even when we explicitly optimise for faithfulness, it may be impossible to guarantee that the surrogate explanations capture the exact characteristics of the black-box decision boundary.
Additionally, surrogates rely on (<strong>random</strong>) <em>data sampling</em> to discover the behaviour of the explained model in a selected neighbourhood.</p>
<p>LIME – Local Interpretable Model-agnostic Explanations <span id="id8">[<a class="reference internal" href="../../bibliography/bibliography.html#id12" title="Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. “Why should I trust you?”: Explaining the predictions of any classifier. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, San Francisco, CA, USA, August 13-17, 2016, 1135–1144. 2016.">Ribeiro <em>et al.</em>, 2016</a>]</span> – is one of the most popular surrogate explainers but it is just a single instantiation of their much broader family.
To cover the breadth and depth of this explainer type, this chapter is based on the bLIMEy – build LIME yourself <span id="id9">[<a class="reference internal" href="../../bibliography/bibliography.html#id16" title="Kacper Sokol, Alexander Hepburn, Raul Santos-Rodriguez, and Peter Flach. bLIMEy: Surrogate prediction explanations beyond LIME. 2019 Workshop on Human-Centric Machine Learning (HCML 2019) at the 33rd Conference on Neural Information Processing Systems (NeurIPS 2019), Vancouver, Canada, 2019. arXiv preprint arXiv:1910.13016. URL: https://arxiv.org/abs/1910.13016.">Sokol <em>et al.</em>, 2019</a>]</span> – meta-algorithm.
It provides a generalisation of LIME into a flexible framework that supports building bespoke surrogate explainers that are appropriate for the problem at hand and exhibit the desired properties.
bLIMEy has three algorithmic steps.</p>
<ol class="arabic simple">
<li><p><em>Interpretable representation composition.</em>
If desired, data are transformed from their original domain into a human-intelligible representation, which is used to convey the explanations.
For example, <a class="reference internal" href="../../preface/glossary.html#term-super-pixel"><span class="xref std std-term">super-pixel</span></a> segmentation of images; <a class="reference internal" href="../../preface/glossary.html#term-bag-of-words"><span class="xref std std-term">bag-of-words</span></a> representation of text; and discretisation of continuous features for tabular data.
While this step is required for the former two domains, it is not necessary – albeit helpful – for the latter.</p></li>
<li><p><em>Data sampling.</em>
To capture the behaviour of a black box in a desired subspace, a data sample is generated and predicted by the explained model.</p></li>
<li><p><em>Explanation generation.</em>
Explanatory insights are extracted from an inherently transparent model fitted into the data sampled in the previous step, using their black-box predictions as the target.
Additional processing steps can be applied to tune and tweak the surrogate model, hence the explanation.
For example, the sample can be <em>weighted</em> based on its proximity to the explained instance when dealing with local explanations; and a feature selection procedure may be used to introduce sparsity, therefore improve accessibility and comprehensibility of explanatory insights.</p></li>
</ol>
<p>These steps are operationalised differently depending on the type of data, hence their algorithmic approaches are covered by separate sections of this chapter (see the table below).
A visual depiction of a step-by-step process of building a <em>local</em>, <em>linear</em> surrogate for two-dimensional <em>tabular data</em> <em>without an interpretable representation</em> is captured by <a class="reference internal" href="intro.html#fig-surrogates-full-overview"><span class="std std-numref">Figure 1.2</span></a>.</p>
<h2> High-level Summary </h2>
<p>Surrogate explainers may be a good solution, or should be avoided, depending on individual circumstances.</p>
<h3> Pros </h3>
<ul class="simple">
<li><p>A universal inspection mechanism for various subspaces of an arbitrary black-box algorithmic decision process.</p></li>
<li><p>Highly customisable.</p></li>
<li><p>A single explanatory procedure for image, text and tabular data.</p></li>
<li><p>Produces diverse explanation types depending on the utilised surrogate model.</p></li>
<li><p>Outputs intuitive explanations for image and text data due to the use of interpretable representations.</p></li>
</ul>
<h3> Cons </h3>
<ul class="simple">
<li><p>Inadequate for high-stakes algorithmic decisions because of lacklustre fidelity <span id="id10">[<a class="reference internal" href="../../bibliography/bibliography.html#id15" title="Cynthia Rudin. Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead. Nature Machine Intelligence, 1(5):206–215, 2019.">Rudin, 2019</a>]</span>.</p></li>
<li><p>Explanations may be counterintuitive and misleading for a lay audience when applied to tabular data <em>with</em> an interpretable representation.</p></li>
<li><p>While post-hoc, model-agnostic and data-universal, they must not be treated as a silver bullet.</p></li>
<li><p>Their characteristics allow a single instantiation of a surrogate explainer to be applied to diverse problems, however the quality of the resulting explanations will vary across different problems and data sets.</p></li>
<li><p>Building them requires an effort since each explainer should be tweaked and tuned to the problem at hand.</p></li>
</ul>
<h2> Popular Surrogate Explainers </h2>
<p>The following approaches are popular in the space of surrogate explainers.</p>
<ul class="simple">
<li><p>LIME – Local Interpretable Model-agnostic Explanations <span id="id11">[<a class="reference internal" href="../../bibliography/bibliography.html#id12" title="Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. “Why should I trust you?”: Explaining the predictions of any classifier. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, San Francisco, CA, USA, August 13-17, 2016, 1135–1144. 2016.">Ribeiro <em>et al.</em>, 2016</a>]</span> – is a <em>local</em> surrogate explainer based on a <em>linear model</em>. Its explanations capture the influence of human-intelligible components, which are determined by the underlying interpretable representation, on a selected black-box prediction. It works with text, image and tabular data.</p></li>
<li><p>bLIMEy – build LIME yourself <span id="id12">[<a class="reference internal" href="../../bibliography/bibliography.html#id16" title="Kacper Sokol, Alexander Hepburn, Raul Santos-Rodriguez, and Peter Flach. bLIMEy: Surrogate prediction explanations beyond LIME. 2019 Workshop on Human-Centric Machine Learning (HCML 2019) at the 33rd Conference on Neural Information Processing Systems (NeurIPS 2019), Vancouver, Canada, 2019. arXiv preprint arXiv:1910.13016. URL: https://arxiv.org/abs/1910.13016.">Sokol <em>et al.</em>, 2019</a>]</span> – is a surrogate meta-algorithm that provides a generic framework for building bespoke surrogate explainers.</p></li>
</ul>
<p><a class="reference internal" href="intro.html#text-meta-explainers-surrogates-overview-literature"><span class="std std-numref">Section 1.1.7</span></a> offers a broader overview of relevant literature.</p>
<h2> Implementations </h2>
<p>The following software packages implement surrogate explainers.
Note that many packages only offer an interface to the official LIME implementation; these instances are marked with the <span class="far fa-lemon"></span> symbol.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p><span class="fab fa-python"></span> Python</p></th>
<th class="head"><p><span class="fab fa-r-project"></span> R</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><a class="reference external" href="https://github.com/marcotcr/lime">LIME</a></p></td>
<td><p><a class="reference external" href="https://github.com/thomasp85/lime">lime</a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://github.com/interpretml/interpret">interpret</a> <span class="far fa-lemon"></span></p></td>
<td><p><a class="reference external" href="https://github.com/christophM/iml">iml</a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference external" href="https://github.com/oracle/Skater">Skater</a> <span class="far fa-lemon"></span></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://github.com/Trusted-AI/AIX360">AIX360</a> <span class="far fa-lemon"></span></p></td>
<td></td>
</tr>
</tbody>
</table>
</div>
<h2> Contents of This Chapter </h2>
<p>This chapter is split into sections dedicated to different types of data – <a class="reference internal" href="text.html#text-meta-explainers-surrogates-text"><span class="std std-ref">text</span></a>, <a class="reference internal" href="image.html#text-meta-explainers-surrogates-image"><span class="std std-ref">image</span></a> and <a class="reference internal" href="tabular/index.html#text-meta-explainers-surrogates-tabular"><span class="std std-ref">tabular</span></a> – each one covering the three components of surrogate explainers.
It is loosely based on a 2020 ECML-PKDD hands-on tutorial titled
<a class="reference external" href="https://events.fat-forensics.org/2020_ecml-pkdd"><em>What and How of Machine Learning Transparency: Building Bespoke Explainability Tools with Interoperable Algorithmic Components</em></a> <span id="id13">[<a class="reference internal" href="../../bibliography/bibliography.html#id17" title="Kacper Sokol, Alexander Hepburn, Raul Santos-Rodriguez, and Peter Flach. What and how of machine learning transparency: Building bespoke explainability tools with interoperable algorithmic components. Journal of Open Source Education, 5(58):175, 2022. URL: https://doi.org/10.21105/jose.00175, doi:10.21105/jose.00175.">Sokol <em>et al.</em>, 2022</a>]</span>.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"></th>
<th class="head"><p>Text</p></th>
<th class="head"><p>Image</p></th>
<th class="head"><p>Tabular</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Overview</strong></p></td>
<td><p><a class="reference internal" href="text.html#text-meta-explainers-surrogates-text"><span class="std std-numref">§1.2</span></a></p></td>
<td><p><a class="reference internal" href="image.html#text-meta-explainers-surrogates-image"><span class="std std-numref">§1.3</span></a></p></td>
<td><p><a class="reference internal" href="tabular/index.html#text-meta-explainers-surrogates-tabular"><span class="std std-numref">§1.4</span></a></p></td>
</tr>
<tr class="row-odd"><td><p><strong>Interpretable Representation</strong></p></td>
<td><p><a class="reference internal" href="text.html#text-meta-explainers-surrogates-text-interpretable-representation"><span class="std std-numref">§1.2.1</span></a></p></td>
<td><p><code class="xref std std-numref docutils literal notranslate"><span class="pre">§%s</span></code></p></td>
<td><p><a class="reference internal" href="tabular/interpretable_representation.html#text-meta-explainers-surrogates-tabular-interpretable-representation"><span class="std std-numref">§1.4.1</span></a></p></td>
</tr>
<tr class="row-even"><td><p><strong>Data Sampling</strong></p></td>
<td><p><a class="reference internal" href="text.html#text-meta-explainers-surrogates-text-data-sampling"><span class="std std-numref">§1.2.2</span></a></p></td>
<td><p><code class="xref std std-numref docutils literal notranslate"><span class="pre">§%s</span></code></p></td>
<td><p><a class="reference internal" href="tabular/data_sampling.html#text-meta-explainers-surrogates-tabular-data-sampling"><span class="std std-numref">§1.4.2</span></a></p></td>
</tr>
<tr class="row-odd"><td><p><strong>Explanation Generation</strong></p></td>
<td><p><a class="reference internal" href="text.html#text-meta-explainers-surrogates-text-explanation-generation"><span class="std std-numref">§1.2.3</span></a></p></td>
<td><p><code class="xref std std-numref docutils literal notranslate"><span class="pre">§%s</span></code></p></td>
<td><p><a class="reference internal" href="tabular/explanation_generation.html#text-meta-explainers-surrogates-tabular-explanation-generation"><span class="std std-numref">§1.4.3</span></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="toctree-wrapper compound">
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./book/meta_explainers/surrogates"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../index.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Meta-Explainers</p>
      </div>
    </a>
    <a class="right-next"
       href="intro.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">1.1. </span>Overview</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By <a href="mailto:kacper@xmlx.dev">Kacper Sokol</a> and <a href="mailto:team@xmlx.dev">XMLX Team</a> &ndash; <a href="https://xmlx.dev/">xmlx.dev</a>. <br> Book distributed under <a href="https://github.com/xmlx-dev/xml-book/blob/master/LICENCE">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International Licence</a>. <br> Code distributed under <a href="https://github.com/xmlx-dev/xml-book/blob/master/LICENCE-code"> MIT Licence</a>.

</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2021–2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  <p> This book delivers a comprehensive outlook on the most popular explainability concepts in Machine Learning. It covers a range of theoretical and practical topics across different difficulty levels, including but not limited to: high-level overviews & introductory examples; mathematical foundations; algorithmic implementations; practical advice & real-life caveats; and success & failure case studies. </p>

</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>